{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "path1p = os.path.dirname(currentdir)\n",
    "path2p = os.path.dirname(path1p)\n",
    "libpath = os.path.join(path2p, \"lib\")\n",
    "\n",
    "sys.path.insert(0, libpath) \n",
    "print(\"Appended library directory\", libpath)\n",
    "\n",
    "# User libraries\n",
    "from signal_lib import resample\n",
    "from data_io.qt_wrapper import gui_fnames, gui_fpath\n",
    "from data_io.yaro.yaro_te_h5_lib import readTE_H5, getStatistics, parseTEfolders, flatten_param_sweep\n",
    "import plots.te_plots as te_plots\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing single point data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get datasets and parse them\n",
    "path_tmp = \"/mnt/hifo_scratch1/Yaro/TE_from_Aleksejs/data_idtxl/swipe/specific-param-study\"\n",
    "parsed_te_datasets_dict = parseTEfolders(path_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "for dataname, dataval in parsed_te_datasets_dict.items():\n",
    "    dataval['data'] = np.array([readTE_H5(filepath) for filepath in dataval[\"filepaths\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swipe Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:\n",
    "1) Plot: Diff nlinks between two datasets\n",
    "2) Plot: Shared/Overlap links between two datasets\n",
    "\n",
    "**Later**\n",
    "1) Convert storage to PANDAS\n",
    "2) Adequately rename folders in structure\n",
    "3) Separate plots from main code, save figures to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestep_from_filename(fname):\n",
    "    if \"raw\" in fname:\n",
    "        return 0.05 # seconds\n",
    "    elif \"subsample\" in fname:\n",
    "        return 0.2 # seconds\n",
    "    else:\n",
    "        raise ValueError(\"Can't figure out timestep from\", fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output folder\n",
    "outpath = gui_fpath(\"Select folder for output images\", \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# time : Total Number of links - By Timestep\n",
    "#################################\n",
    "for dataname, dataval in parsed_te_datasets_dict.items():\n",
    "    timestep = timestep_from_filename(dataname)\n",
    "    \n",
    "    # Precompute parameter sweep\n",
    "    param_sweep_keys = ['isAnalysis', 'isMouse', 'isTrial', 'isRange', 'isMethod']\n",
    "    param_sweep_dicts = [dataval[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep = flatten_param_sweep(param_sweep_dicts, dataval[\"summary\"][\"dataname\"])\n",
    "\n",
    "    for title_suffix, idxs in zip(*param_sweep):\n",
    "        data_lst  = dataval['data'][idxs.astype(bool)]\n",
    "        label_lst = dataval['filenames'][idxs.astype(bool)]\n",
    "        \n",
    "        # Plotting connection number\n",
    "        outfname = os.path.join(outpath, \"nconn_bytime_\" + title_suffix + \".png\")\n",
    "        te_plots.plot_te_nconn_bytime(outfname, data_lst, label_lst, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# Session : Total number of links - Range By Days\n",
    "################################################\n",
    "time2step = lambda t:  int(t / 10.0 * N_TIMES)   # FIXME\n",
    "\n",
    "ranges_sec  = {'TEX' : (2.0, 3.5), 'LIK' : (3.5, 6.0)}\n",
    "ranges_step = {k, (times2step(v[0]), times2step(v[1])) for k,v in ranges_sec.items()}\n",
    "\n",
    "for dataname, dataval in parsed_te_datasets_dict.items():\n",
    "    timestep = timestep_from_filename(dataname)\n",
    "    \n",
    "    # Precompute parameter sweep\n",
    "    param_sweep_keys = ['isAnalysis', 'isMouse', 'isTrial', 'isMethod']\n",
    "    param_sweep_dicts = [dataval[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep = flatten_param_sweep(param_sweep_dicts, dataval[\"summary\"][\"dataname\"])\n",
    "\n",
    "    for title_suffix, idxs in zip(*param_sweep):\n",
    "        data_lst  = dataval['data'][idxs.astype(bool)]\n",
    "        label_lst = dataval['filenames'][idxs.astype(bool)]\n",
    "        \n",
    "        # Plotting connection number\n",
    "        for rng_name, rng_sec in ranges_sec.items():\n",
    "            outfname = os.path.join(outpath, \"nconn_rangebytime_\" + rng_name + \"_\" + title_suffix + \".png\")\n",
    "            te_plots.plot_te_nconn_rangebydays(outfname, data_lst, label_lst, ranges_step, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# Session : Shared Link Scatter\n",
    "#################################\n",
    "for dataname, dataval in parsed_te_datasets_dict.items():\n",
    "    timestep = timestep_from_filename(dataname)\n",
    "    \n",
    "    # Precompute parameter sweep\n",
    "    param_sweep_keys = ['isAnalysis', 'isMouse', 'isTrial', 'isMethod']\n",
    "    param_sweep_dicts = [dataval[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep = flatten_param_sweep(param_sweep_dicts, dataval[\"summary\"][\"dataname\"])\n",
    "\n",
    "    for title_suffix, idxs in zip(*param_sweep):\n",
    "        data_lst  = dataval['data'][idxs.astype(bool)]\n",
    "        label_lst = dataval['filenames'][idxs.astype(bool)]\n",
    "        \n",
    "        # Plotting connection number\n",
    "        outfname = os.path.join(outpath, \"shared_link_scatter_\" + title_suffix + \".png\")\n",
    "        te_plots.plot_te_shared_link_scatter(outfname, data_lst, label_lst, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Distribution of TE\n",
    "#################################\n",
    "timestep = 0.2 # FIXME\n",
    "\n",
    "for dataname, dataval in parsed_te_datasets_dict.items():\n",
    "    timestep = timestep_from_filename(dataname)\n",
    "    \n",
    "    # Precompute parameter sweep\n",
    "    param_sweep_keys = ['isAnalysis', 'isMouse', 'isTrial', 'isRange', 'isMethod']\n",
    "    param_sweep_dicts = [dataval[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep = flatten_param_sweep(param_sweep_dicts, dataval[\"summary\"][\"dataname\"])\n",
    "\n",
    "    for title_suffix, idxs in zip(*param_sweep):\n",
    "        data_lst  = dataval['data'][idxs.astype(bool)]\n",
    "        label_lst = dataval['filenames'][idxs.astype(bool)]\n",
    "        \n",
    "        # Plotting TE distribution\n",
    "        outfname = os.path.join(outpath, \"te_distr_\" + title_suffix + \".png\")\n",
    "        te_plots.plot_te_distribution(outfname, data_lst, label_lst, timestep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# time : Relative difference between number of links\n",
    "#################################\n",
    "def comp_rel_diff_nconn(dataname1, dataname2):\n",
    "    dt1 = timestep_from_filename(dataname1)\n",
    "    dt2 = timestep_from_filename(dataname2)\n",
    "    \n",
    "    dataval1 = parsed_te_datasets_dict[dataname1]\n",
    "    dataval2 = parsed_te_datasets_dict[dataname2]\n",
    "    dataname_diff = dataname1 + \"_\" + dataname2\n",
    "    \n",
    "    # Precompute parameter sweep\n",
    "    param_sweep_keys = ['isAnalysis', 'isMouse', 'isTrial', 'isRange', 'isMethod']\n",
    "    param_sweep_dicts1 = [dataval1[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep_dicts2 = [dataval1[\"statistics\"][key] for key in param_sweep_keys]\n",
    "    param_sweep1 = flatten_param_sweep(param_sweep_dicts, dataname_diff)\n",
    "    param_sweep2 = flatten_param_sweep(param_sweep_dicts, dataname_diff)\n",
    "    assert len(param_sweep1)==len(param_sweep2), \"All names in two datasets must match\"\n",
    "    \n",
    "    for title_suffix, idxs in zip(*param_sweep1):\n",
    "        data_lst1  = dataval1['data'][idxs.astype(bool)]\n",
    "        data_lst2  = dataval2['data'][idxs.astype(bool)]\n",
    "        label_lst1 = dataval1['filenames'][idxs.astype(bool)]\n",
    "        label_lst2 = dataval2['filenames'][idxs.astype(bool)]\n",
    "        \n",
    "        # Plotting TE distribution\n",
    "        outfname = os.path.join(outpath, \"nconn_diff_bytime_\" + title_suffix + \".png\")\n",
    "        te_plots.plot_te_rel_diff_nlinks_bytime(outfname, data_lst1, data_lst2, label_lst1, label_lst2, dt1, dt2)\n",
    "        \n",
    "comp_rel_diff_nconn('raw_delay_2_window_3',       'raw_delay_2_window_10')\n",
    "comp_rel_diff_nconn('raw_delay_2_window_3',       'subsample_delay_2_window_6')\n",
    "comp_rel_diff_nconn('raw_delay_2_window_10',      'subsample_delay_5_window_6')\n",
    "comp_rel_diff_nconn('subsample_delay_2_window_6', 'subsample_delay_5_window_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Degree Distribution\n",
    "#################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "  For each dataset, for each file, for each param combination\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# Neuron Labels\n",
    "#labels = ['Cpu', 'GP', 'Rt', 'S1_bf', 'LD', 'VM', 'VL', 'CA1', 'CA1_Py', 'CA1_Mol', 'DG', 'M1']\n",
    "labels = ['Cpu','GP','Po','S1_bf','VM','VL','LDVL','M1','CA1_Py','LHb','cc','cc']\n",
    "pd.DataFrame({i : l for i,l in enumerate(labels)}, index=[\"Region Name\"])\n",
    "\n",
    "# # Behaviour Labels\n",
    "# labels = ['lick', 'paw', 'Start Cue', 'End Cue', 'Reward', 'First Touch']\n",
    "# pd.DataFrame({i : l for i,l in enumerate(labels)}, index=[\"Behaviour\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Range Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isCorrectMouse = np.array([mname == 'mtp_15' for mname in mouse_names], dtype=int)\n",
    "\n",
    "fig1, ax1 = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "fig2, ax2 = plt.subplots(nrows=2, ncols=3, figsize=(15, 5), tight_layout=True)\n",
    "\n",
    "for i, trial in enumerate([\"ALL\"]):\n",
    "    for j, method in enumerate([\"BTE\",\"MTE\"]):\n",
    "        ax2[j][0].set_ylabel(method)\n",
    "        \n",
    "        for k, rng in enumerate([\"CUE\", \"TEX\", \"LIK\"]):\n",
    "            ax2[0][k].set_title(rng)\n",
    "            \n",
    "            idxs_ths = isCorrectMouse + isAnalysis[\"range\"] + isTrial[trial] + isMethod[method] + isRange[rng] == 5\n",
    "            print(\"For trials\", trial,\"range\", rng,\"method\", method, \"have\", np.sum(idxs_ths), \"files\")\n",
    "            \n",
    "            nConn = []\n",
    "            actSum = np.zeros((12,12))\n",
    "            for fname, basename in zip(datafilenames[idxs_ths], basenames[idxs_ths]):\n",
    "#                 print(\"Processing file: \", basename)\n",
    "                te, lag, p = getData(fname)\n",
    "\n",
    "                isActive = 1-np.isnan(te).astype(int)\n",
    "                actSum += isActive\n",
    "                nConn += [np.sum(isActive) / (te.shape[0]**2 - te.shape[0])]\n",
    "#                 totalConnPerConn[-1][-1].append(np.sum(1-np.isnan(te).astype(int), axis=2).flatten()  / (te.shape[0]**2 - te.shape[0]))\n",
    "\n",
    "            ax1[j].plot(nConn, label=rng)\n",
    "            ax2[j][k].imshow(actSum)\n",
    "    \n",
    "        ax1[j].set_title(method)\n",
    "        ax1[j].set_xlabel(\"day/file\")\n",
    "        ax1[j].set_ylabel(\"ratio of active connections\")\n",
    "        ax1[j].legend()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in [\"BivariateTE\", \"MultivariateTE\"]:\n",
    "#     for i in range(16, 20):\n",
    "#         for rng in [\"CUE\", \"TEX\", \"LIK\"]:\n",
    "#             fname = \"mtp_15_2018_05_\" + str(i) + \"_a_\" + model + \"_range_\" + rng + \".h5\"\n",
    "#             te, lag, p = getData(fname)\n",
    "            \n",
    "#             fig, ax = plt.subplots(ncols = 3, figsize=(15, 5))\n",
    "#             ax[0].imshow(te[:,:], cmap=\"jet\", vmin=0, vmax=1)\n",
    "#             ax[1].imshow(lag[:,:], cmap=\"jet\", vmin=1, vmax=5)\n",
    "#             ax[2].imshow(p[:,:], cmap=\"jet\", vmin=0, vmax=1)\n",
    "#             ax[0].set_title(\"TE\")\n",
    "#             ax[1].set_title(\"delay\")\n",
    "#             ax[2].set_title(\"p-value\")\n",
    "            \n",
    "#             fig.suptitle(fname)\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing swipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bte_te, bte_lag, bte_p = getData(\"mtp_15_2018_05_19_a_BivariateTE_swipe.h5\")\n",
    "mte_te, mte_lag, mte_p = getData(\"mtp_15_2018_05_19_a_MultivariateTE_swipe.h5\")\n",
    "\n",
    "# Interactive\n",
    "def f(i):\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols = 3, figsize=(12, 8))\n",
    "    ax[0][0].imshow(bte_te[:,:,i], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[1][0].imshow(mte_te[:,:,i], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[0][1].imshow(bte_lag[:,:,i], cmap=\"jet\", vmin=1, vmax=5)\n",
    "    ax[1][1].imshow(mte_lag[:,:,i], cmap=\"jet\", vmin=1, vmax=5)\n",
    "    ax[0][2].imshow(bte_p[:,:,i], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    ax[1][2].imshow(mte_p[:,:,i], cmap=\"jet\", vmin=0, vmax=1)\n",
    "    \n",
    "    ax[0][0].set_ylabel(\"Bivariate\")\n",
    "    ax[1][0].set_ylabel(\"Multivatiate\")\n",
    "    ax[0][0].set_title(\"TE\")\n",
    "    ax[0][1].set_title(\"delay\")\n",
    "    ax[0][2].set_title(\"p-value\")\n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot = interactive(f, i=(0, bte_te.shape[2]-1, 1))\n",
    "output = interactive_plot.children[-1]\n",
    "output.layout.height = '500px'\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
