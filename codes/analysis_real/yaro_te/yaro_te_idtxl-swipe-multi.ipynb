{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended library directory /home/alfomi/work/mesoscopic-functional-connectivity/codes/lib\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import h5py\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "# Append base directory\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "path1p = os.path.dirname(currentdir)\n",
    "path2p = os.path.dirname(path1p)\n",
    "libpath = os.path.join(path2p, \"lib\")\n",
    "\n",
    "sys.path.insert(0, libpath)\n",
    "print(\"Appended library directory\", libpath)\n",
    "\n",
    "# User libraries\n",
    "from data_io.os_lib import getfiles_walk\n",
    "from data_io.yaro.yaro_data_read import read_neuro_perf\n",
    "from signal_lib import resample\n",
    "from fc.te_idtxl_wrapper import idtxlParallelCPUMulti, idtxlResultsParse\n",
    "from qt_wrapper import gui_fpath\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Neuronal Data\n",
    "\n",
    "The neuronal data for a given experiment is given by the 3D matrix of dimensions `[N_Trial, N_Times, N_Channels]`\n",
    "\n",
    "Notes:\n",
    "* `DT = 0.05` : the sampling interval is always 50ms\n",
    "* `N_Times = 201` : the total experiment time is always 10s. All experiments are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Declare constants\n",
    "params = {\n",
    "    \"exp_timestep\" : 0.05, # 50ms, the standard measurement interval\n",
    "    \"bin_timestep\" : 0.2,  # 200ms, the binned interval\n",
    "    \n",
    "    # The standard timesteps for different scenarios\n",
    "    \"range_CUE\" : (1.0, 1.5),    # 1-1.5 seconds trial time\n",
    "    \"range_TEX\" : (2.0, 3.5),    # 2-3.5 seconds trial time\n",
    "    \"range_LIK\" : (3.5, 6.0),    # 3.5-6 seconds trial time\n",
    "    \"range_ALL\" : (0.0, 10.0),   # 0-10  seconds\n",
    "\n",
    "#     \"samples_window\" : \"ALL\",\n",
    "    \"trial_types\" : [\"iGO\", \"iNOGO\"],\n",
    "    \"resample\"    : {'method' : 'averaging', 'kind' : 'kernel'}  # None if raw data is prefered\n",
    "#     \"subsampling_windows_lenghts\" : 4*np.ones((1,51)),  #uniform subsampling, 50 bins\n",
    "\n",
    "#     \"te_delay_stepsize\" : 1,\n",
    "#     \"te_receiver_embedding_tau\" : 1,\n",
    "#     \"te_sampling_rate\" : 20\n",
    "}\n",
    "\n",
    "idtxl_settings = {\n",
    "    'dim_order'       : 'rsp',\n",
    "    'methods'         : [\"BivariateTE\", \"MultivariateTE\"],\n",
    "    'cmi_estimator'   : 'JidtGaussianCMI',\n",
    "    'min_lag_sources' : 1,\n",
    "    'max_lag_sources' : 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dirname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_16_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_17_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_18_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_19_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_22_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_23_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_24_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_25_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_29_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_30_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_05_31_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_06_01_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtp_15_2018_06_04_a</th>\n",
       "      <td>/mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               dirname\n",
       "mtp_15_2018_05_16_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_17_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_18_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_19_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_22_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_23_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_24_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_25_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_29_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_30_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_05_31_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_06_01_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15...\n",
       "mtp_15_2018_06_04_a  /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get paths\n",
    "root_path = gui_fpath(\"Path to root folder containing neuronal data\", \"./\")\n",
    "pathswalk = getfiles_walk(root_path, ['behaviorvar.mat'])\n",
    "datapaths = {os.path.basename(path) : path for path, file in pathswalk}\n",
    "pd.DataFrame(datapaths, index=['dirname']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_path  = gui_fpath(\"Path where to save results\", \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swipe Transfer Entropy via IDTxl\n",
    "\n",
    "Notation of IDTxl\n",
    "* `(processes, samples, replications)` equivalent to ours `(channels, times, trials)`\n",
    "* Thus Yaro matrix `(nTrials, nTimes, nChannels)` is given by `'rsp'`, but\n",
    "* For example `(nChannels, nTimes)` would be `'ps'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Yaro data from /mnt/hifo_scratch1/Yaro/data_for_TE/mtp/mtp_15/mtp_15_2018_05_16_a\n",
      "Loaded neuronal data with (nTrials, nTimes, nChannels)= (338, 201, 12)\n",
      "Downsampling from 0.05 ms to 0.2 ms\n",
      "After downsampling data shape is (nTrials, nTimes, nChannels)= (338, 50, 12)\n",
      "For trialType = iGO the shape is (nTrials, nTimes, nChannels)= (154, 50, 12)\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "Adding data with properties: 12 processes, 6 samples, 154 replications\n",
      "overwriting existing data\n",
      "\n",
      "Target: 3 - testing sources [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Target: 1 - testing sources [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Target: 0 - testing sources [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "---------------------------- (1) include target candidates\n",
      "\n",
      "\n",
      "Target: 2 - testing sources [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11]candidate set: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "\n",
      "candidate set: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "candidate set: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "\n",
      "---------------------------- (1) include target candidatestesting candidate: (1, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "Target: 5 - testing sources [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "Target: 4 - testing sources [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "Target: 6 - testing sources [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11]\n",
      "---------------------------- (1) include target candidates\n",
      "\n",
      "candidate set: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "candidate set: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "\n",
      "Target: 9 - testing sources [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11]\n",
      "candidate set: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "testing candidate: (4, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "Target: 7 - testing sources [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11]testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "\n",
      "Target: 8 - testing sources [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11]candidate set: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (5, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "\n",
      "candidate set: [(9, 1), (9, 2), (9, 3), (9, 4), (9, 5)]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "---------------------------- (1) include target candidates\n",
      "testing candidate: (9, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "\n",
      "Target: 10 - testing sources [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11]testing candidate: (6, 1) maximum statistic, n_perm: 200\n",
      "candidate set: [(7, 1), (7, 2), (7, 3), (7, 4), (7, 5)]\n",
      "candidate set: [(8, 1), (8, 2), (8, 3), (8, 4), (8, 5)]\n",
      "\n",
      "testing candidate: (7, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "---------------------------- (1) include target candidatestesting candidate: (8, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "candidate set: [(10, 1), (10, 2), (10, 3), (10, 4), (10, 5)]\n",
      "testing candidate: (10, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (4, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (7, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (8, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (9, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (10, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing candidate: (0, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (4, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (8, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (9, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (10, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (9, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (10, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (8, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      " -- not significant\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "\n",
      "---------------------------- (2) include source candidatescandidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      " -- not significant\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (6, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (6, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      " -- not significant\n",
      "testing candidate: (4, 4) maximum statistic, n_perm: 200\n",
      "candidate set current source: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (6, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (6, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "testing candidate: (5, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "\n",
      "Target: 11 - testing sources [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "Target: 0 - testing sources [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "candidate set: [(11, 1), (11, 2), (11, 3), (11, 4), (11, 5)]\n",
      "\n",
      "---------------------------- (1) include target candidates\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-af151c128cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdata_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnTimes\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mteWindow\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mdata_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataEff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mteWindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mrez\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midtxlParallelCPUMulti\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midtxl_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolderName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miMethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midtxl_settings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'methods'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/mesoscopic-functional-connectivity/codes/lib/fc/te_idtxl_wrapper.py\u001b[0m in \u001b[0;36midtxlParallelCPUMulti\u001b[0;34m(data_lst, settings, taskName, NCore)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrez\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mrez_multilst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiParallelTask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msweepLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mtripleIdxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweepLst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweepLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/site-packages/pathos/multiprocessing.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, f, *args, **kwds)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mAbstractWorkerPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AbstractWorkerPool__map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# chunksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractWorkerPool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/site-packages/multiprocess/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/py3idtxl/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate set: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (11, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "Target: 1 - testing sources [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "candidate set: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "\n",
      "Target: 2 - testing sources [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "candidate set: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "Target: 6 - testing sources [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11]\n",
      "Target: 3 - testing sources [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Target: 5 - testing sources [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "Target: 4 - testing sources [0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "\n",
      "\n",
      "---------------------------- (1) include target candidatescandidate set: [(5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]\n",
      "candidate set: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "\n",
      "candidate set: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (5, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "testing candidate: (4, 1) maximum statistic, n_perm: 200\n",
      "candidate set: [(6, 1), (6, 2), (6, 3), (6, 4), (6, 5)]\n",
      "testing candidate: (6, 1) maximum statistic, n_perm: 200\n",
      "\n",
      "Target: 7 - testing sources [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11]\n",
      "\n",
      "---------------------------- (1) include target candidates\n",
      "candidate set: [(7, 1), (7, 2), (7, 3), (7, 4), (7, 5)]\n",
      "testing candidate: (7, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (11, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (4, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (7, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (11, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (5, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (4, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (3, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 3) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (1, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      "testing candidate: (0, 4) maximum statistic, n_perm: 200\n",
      "testing candidate: (11, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidatestesting candidate: (5, 4) maximum statistic, n_perm: 200\n",
      "\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (11, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 5) maximum statistic, n_perm: 200\n",
      "testing candidate: (6, 5) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "\n",
      "---------------------------- (2) include source candidates\n",
      "candidate set current source: [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]\n",
      "testing candidate: (0, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      " -- not significant\n",
      "testing candidate: (1, 5) maximum statistic, n_perm: 200\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5)]\n",
      "testing candidate: (1, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 4) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 2) maximum statistic, n_perm: 200\n",
      "testing candidate: (2, 3) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n",
      "testing candidate: (4, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(3, 1), (3, 2), (3, 3), (3, 4), (3, 5)]\n",
      "testing candidate: (3, 1) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(2, 1), (2, 2), (2, 3), (2, 4), (2, 5)]\n",
      "testing candidate: (2, 2) maximum statistic, n_perm: 200\n",
      " -- not significant\n",
      "candidate set current source: [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing candidate: (4, 1) maximum statistic, n_perm: 200\n"
     ]
    }
   ],
   "source": [
    "for folderName, folderPathName in datapaths.items():\n",
    "    \n",
    "    #############################\n",
    "    # Reading and downsampling\n",
    "    #############################\n",
    "\n",
    "    # Read LVM file from command line\n",
    "    data, behaviour = read_neuro_perf(folderPathName)\n",
    "\n",
    "    # Get parameters\n",
    "    nTrials, nTimes, nChannels = data.shape\n",
    "    print(\"Loaded neuronal data with (nTrials, nTimes, nChannels)=\", data.shape)\n",
    "\n",
    "    assert nTimes == 201, \"The number of timesteps must be 201 for all data, got \"+str(nTimes)\n",
    "    \n",
    "\n",
    "    # Timeline (x-axis)\n",
    "    tlst = params[\"exp_timestep\"] * np.linspace(0, nTimes, nTimes)\n",
    "\n",
    "    # Downsample data\n",
    "    if params[\"resample\"] is not None:\n",
    "        print(\"Downsampling from\", params[\"exp_timestep\"], \"ms to\", params[\"bin_timestep\"], \"ms\")\n",
    "        params[\"timestep\"] = params[\"bin_timestep\"]\n",
    "        nTimesDownsampled = int(nTimes * params[\"exp_timestep\"] / params[\"timestep\"])\n",
    "        tlst_down = params[\"timestep\"] * np.linspace(0, nTimesDownsampled, nTimesDownsampled)\n",
    "        data_down = np.array([[resample(tlst, data[i, :, j], tlst_down, params[\"resample\"])\n",
    "                              for i in range(nTrials)] \n",
    "                             for j in range(nChannels)])\n",
    "        \n",
    "        # Replace old data with subsampled one    \n",
    "        tlst, data = tlst_down, data_down.transpose(1, 2, 0)\n",
    "        nTrials, nTimes, nChannels = data.shape\n",
    "        print(\"After downsampling data shape is (nTrials, nTimes, nChannels)=\", data.shape)\n",
    "        \n",
    "#         # Plot downsampling for comparison\n",
    "#         plt.figure()\n",
    "#         plt.plot(tlst, data[0, :, 0], label='original')\n",
    "#         plt.plot(tlst_new, data_new[0, 0, :], '.-', label='downsampled')\n",
    "#         plt.title(\"Example before and after downsampling\")\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "    else:\n",
    "        params[\"timestep\"] = params[\"exp_timestep\"]\n",
    "\n",
    "        \n",
    "    for trialType in params['trial_types']:\n",
    "        \n",
    "        if trialType is None:\n",
    "            dataEff = data\n",
    "            fileNameSuffix = \"\"\n",
    "        else:\n",
    "            dataEff = data[behaviour[trialType] - 1]\n",
    "            fileNameSuffix = \"_\" + trialType\n",
    "            print(\"For trialType =\", trialType, \"the shape is (nTrials, nTimes, nChannels)=\", dataEff.shape)\n",
    "\n",
    "        #############################\n",
    "        # Analysis\n",
    "        #############################\n",
    "\n",
    "        teWindow = idtxl_settings[\"max_lag_sources\"] + 1\n",
    "\n",
    "        data_range = list(range(nTimes - teWindow + 1))\n",
    "        data_lst = [dataEff[:, i:i + teWindow, :] for i in data_range]\n",
    "        rez = idtxlParallelCPUMulti(data_lst, idtxl_settings, folderName)\n",
    "\n",
    "        for iMethod, method in enumerate(idtxl_settings['methods']):\n",
    "            te_data = np.full((3, nChannels, nChannels, nTimes), np.nan)\n",
    "            \n",
    "            for iRange in data_range:\n",
    "                te_data[..., iRange + idtxl_settings[\"max_lag_sources\"]] = np.array(\n",
    "                    idtxlResultsParse(rez[iMethod][iRange], nChannels, method=method, storage='matrix')\n",
    "                )\n",
    "\n",
    "            #######################\n",
    "            # Save results to file\n",
    "            #######################\n",
    "            savename = os.path.join(out_path, folderName + fileNameSuffix + '_' + method + '_swipe' + '.h5')\n",
    "            print(savename)\n",
    "\n",
    "            h5f = h5py.File(savename, \"w\")\n",
    "\n",
    "            grp_rez = h5f.create_group(\"results\")\n",
    "            grp_rez['TE_table']    = te_data[0]\n",
    "            grp_rez['delay_table'] = te_data[1]\n",
    "            grp_rez['p_table']     = te_data[2]\n",
    "\n",
    "            h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36qt5)",
   "language": "python",
   "name": "py36qt5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
