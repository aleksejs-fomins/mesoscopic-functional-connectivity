{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py36qt5/lib/python3.6/site-packages\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import os,sys,inspect\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Append base directory\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "print(currentdir)\n",
    "\n",
    "# path1p = os.path.dirname(currentdir)\n",
    "# libpath = os.path.join(path1p, \"lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User libraries\n",
    "from codes.lib.plots.accuracy_plots import testplots\n",
    "from metrics.graph_lib import offdiag_idx\n",
    "\n",
    "from models.test_lib import noisePure, noiseLPF, sampleTrials\n",
    "from models.dyn_sys import DynSys\n",
    "\n",
    "from fc.te_idtxl_wrapper import idtxlParallelCPU, idtxlResultsParse\n",
    "from signal_lib import resample\n",
    "from aux_functions import merge_dicts\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DynSys_func(param):\n",
    "    zealous_factor = 10\n",
    "    param_tmp = copy.deepcopy(param)\n",
    "    param_tmp['N_DATA'] += zealous_factor\n",
    "    DS = DynSys(param_tmp)\n",
    "    DS.compute()\n",
    "    return np.copy(DS.data[:, zealous_factor:])\n",
    "\n",
    "idtxl_settings = {\n",
    "    'dim_order'       : 'ps',\n",
    "    'method'          : 'MultivariateTE',\n",
    "    'cmi_estimator'   : 'JidtGaussianCMI',\n",
    "    'max_lag_sources' : 1,\n",
    "    'min_lag_sources' : 1}\n",
    "\n",
    "# Set parameters\n",
    "model_param_noisepure = {\n",
    "    'method'      : noisePure,\n",
    "    'N_NODE'      : 12,             # Number of channels \n",
    "    'T_TOT'       : 10,             # seconds, Total simulation time\n",
    "    'DT'          : 0.2,            # seconds, Binned optical recording resolution\n",
    "    'STD'         : 1               # Standard deviation of random data\n",
    "}\n",
    "\n",
    "# Set parameters\n",
    "model_param_lpfsub = {\n",
    "    'method'      : noiseLPF,\n",
    "    'N_NODE'      : 12,             # Number of channels \n",
    "    'T_TOT'       : 10,             # seconds, Total simulation time\n",
    "    'TAU_CONV'    : 0.5,            # seconds, Ca indicator decay constant\n",
    "    'DT_MICRO'    : 0.001,          # seconds, Neuronal spike timing resolution\n",
    "    'DT'          : 0.2,            # seconds, Binned optical recording resolution\n",
    "    'STD'         : 1               # Standard deviation of random data\n",
    "}\n",
    "\n",
    "# Set parameters\n",
    "model_param_dynsys = {\n",
    "    'method'  : DynSys_func,\n",
    "    'ALPHA'   : 0.1,  # 1-connectivity strength\n",
    "    'N_NODE'  : 12,   # Number of variables\n",
    "    'N_DATA'  : 4000, # Number of timesteps\n",
    "    'MAG'     : 0.0,    # Magnitude of input\n",
    "    'T'       : 20,   # Period of input oscillation\n",
    "    'STD'     : 0.2   # STD of neuron noise\n",
    "}\n",
    "\n",
    "model_param_all = {\n",
    "    \"purenoise\"   : model_param_noisepure,\n",
    "    \"lpfsubnoise\" : model_param_lpfsub,\n",
    "    \"dynsys\"      : model_param_dynsys\n",
    "}\n",
    "\n",
    "# True connectivity matrix for this problem\n",
    "N_NODE = 12\n",
    "DS_TMP = DynSys(model_param_dynsys)\n",
    "TRUE_CONN_DS = DS_TMP.M.transpose()\n",
    "TRUE_CONN_DS[TRUE_CONN_DS == 0] = np.nan\n",
    "TRUE_CONN_DICT = {\n",
    "    \"purenoise\"   : np.full((N_NODE, N_NODE), np.nan),\n",
    "    \"lpfsubnoise\" : np.full((N_NODE, N_NODE), np.nan),\n",
    "    \"dynsys\"   :    TRUE_CONN_DS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Width / Depth analysis\n",
    "\n",
    "This analysis tests for Type 1 errors - how frequently a fake link is found. The two flavours are\n",
    "* **Width** - A dataset with a single repetition, but increasing time duration\n",
    "* **Depth** - A dataset with fixed time duration, but increasing repetition count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#####################\n",
    "# Width/Depth Analysis\n",
    "#####################\n",
    "\n",
    "N_NODE = 12  # Number of channels\n",
    "N_STEP = 40  # Number of different data sizes to pick\n",
    "T_STEP = idtxl_settings['max_lag_sources'] + 1   # Data quantity multiplier \n",
    "ndata_lst = (2 * 10**(np.linspace(1.6, 2.9, N_STEP))).astype(int)\n",
    "\n",
    "idtxl_methods = ['BivariateMI', 'MultivariateMI', 'BivariateTE', 'MultivariateTE']\n",
    "\n",
    "for analysis in ['width', 'depth']:\n",
    "    for modelname, model_param in model_param_all.items():\n",
    "        TRUE_CONN = TRUE_CONN_DICT[modelname]\n",
    "\n",
    "        ###################################\n",
    "        # Generate data - takes some time\n",
    "        ###################################\n",
    "        data_lst = []\n",
    "        ndata_eff = np.zeros(N_STEP, dtype=int)\n",
    "        for i, ndata in enumerate(ndata_lst):\n",
    "            print(\"Generating Data\", analysis, modelname, ndata)\n",
    "\n",
    "            model_param['N_NODE'] = N_NODE\n",
    "\n",
    "            if analysis == 'width':\n",
    "                # Generate whole data once\n",
    "                idtxl_settings['dim_order'] = 'ps'\n",
    "                if 'DT' in model_param:\n",
    "                    model_param['T_TOT']  = ndata * T_STEP * model_param['DT'] \n",
    "                else:\n",
    "                    model_param['N_DATA'] = ndata * T_STEP\n",
    "                data = model_param['method'](model_param)\n",
    "                ndata_eff[i] = data.shape[1]\n",
    "            else:\n",
    "                # Generate each trial independently, then concatenate\n",
    "                idtxl_settings['dim_order'] = 'rsp'\n",
    "                if 'DT' in model_param:\n",
    "                    model_param['T_TOT' ] = T_STEP * model_param['DT']\n",
    "                else:\n",
    "                    model_param['N_DATA'] = T_STEP\n",
    "\n",
    "                data = np.array([model_param['method'](model_param) for j in range(ndata)]).transpose((0, 2, 1))\n",
    "                ndata_eff[i] = data.shape[0]\n",
    "                \n",
    "            data_lst += [data]\n",
    "            \n",
    "        for method in idtxl_methods:\n",
    "            idtxl_settings['method'] = method\n",
    "            te_results = np.zeros((3, N_NODE, N_NODE, N_STEP))\n",
    "            \n",
    "            for i, ndata in enumerate(ndata_lst):\n",
    "                print(\"Processing Data\", analysis, method, modelname, ndata)\n",
    "                \n",
    "                # Run calculation\n",
    "                rez = idtxlParallelCPU(data_lst[i], idtxl_settings)\n",
    "\n",
    "                # Parse Data\n",
    "                te_results[..., i] = np.array(idtxlResultsParse(rez, N_NODE, method=method, storage='matrix'))\n",
    "\n",
    "            # Plot\n",
    "            fname = modelname + '_' + str(N_NODE) + method + '_' + analysis\n",
    "            testplots(ndata_eff, te_results, TRUE_CONN, logx=True, percenty=True, pTHR=0.01, h5_fname=fname+'.h5', fig_fname=fname+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal-to-Noise Analysis\n",
    "\n",
    "This analysis tests for Type 2 errors - failure to find true links as a function of SNR. The two flavours are \n",
    "* **Observational Randomness** - white noise is added to final dataset. Study T2 errors as function of SNR\n",
    "* **Occurence Randomness** - dataset with fixed white noise is augmented by additional noise-only trials. Simulates the effect not being present in some trials, or happening at a different time. Study T2 errors as function of ratio of good trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# Generate data\n",
    "################\n",
    "print(\"Generating Data\")\n",
    "\n",
    "idtxl_methods = ['BivariateMI', 'MultivariateMI', 'BivariateTE', 'MultivariateTE']\n",
    "idtxl_settings['dim_order'] = 'rsp'  # Use multiple repetitions\n",
    "\n",
    "N_NODE = 12\n",
    "T_STEP = idtxl_settings['max_lag_sources'] + 1   # Number of timesteps\n",
    "N_TRIAL = 400  # number of trials\n",
    "\n",
    "modelname = \"dynsys\"\n",
    "model_param = model_param_all[\"dynsys\"]\n",
    "model_param['N_NODE'] = N_NODE   # Number of channels\n",
    "model_param['N_DATA'] = T_STEP  # Number of time steps\n",
    "TRUE_CONN = TRUE_CONN_DICT[modelname]\n",
    "\n",
    "data = np.array([model_param['method'](model_param) for j in range(N_TRIAL)]).transpose((0, 2, 1))\n",
    "data /= np.std(data)  # Normalize all data to have unit variance\n",
    "\n",
    "################\n",
    "# Analyse\n",
    "################\n",
    "\n",
    "N_STEP = 40  # Number of different data sizes to pick\n",
    "\n",
    "# Flavours\n",
    "flavours = ['observational', 'occurence']\n",
    "\n",
    "paramRanges = {\n",
    "    'observational'  : np.arange(N_STEP) / (N_STEP),\n",
    "    'occurence'      : np.arange(N_STEP) / (N_STEP-1)\n",
    "}\n",
    "\n",
    "dataLst = {\n",
    "    'observational'  : [snr * data + (1 - snr) * np.random.normal(0, 1, data.shape) for snr in paramRanges['observational']], \n",
    "    'occurence'      : [\n",
    "        np.concatenate(\n",
    "            (data[:int(freq*N_TRIAL)],\n",
    "             np.random.normal(0, 1, (int((1-freq)*N_TRIAL),)+data.shape[1:]  )), axis=0)\n",
    "        for freq in paramRanges['occurence']]\n",
    "}\n",
    "\n",
    "for flavour in flavours:\n",
    "    for method in idtxl_methods:\n",
    "        idtxl_settings['method'] = method\n",
    "        te_results = np.zeros((3, N_NODE, N_NODE, N_STEP))\n",
    "\n",
    "        for i, data in enumerate(dataLst[flavour]):\n",
    "            print(\"Processing Data\", flavour, paramRanges[flavour][i])\n",
    "\n",
    "            # Run calculation\n",
    "            rez = idtxlParallelCPU(dataLst[flavour][i], idtxl_settings)\n",
    "\n",
    "            # Parse Data\n",
    "            te_results[..., i] = np.array(idtxlResultsParse(rez, N_NODE, method=method, storage='matrix'))\n",
    "\n",
    "        # Plot\n",
    "        fname = modelname + '_' + str(N_NODE) + method + '_' + flavour\n",
    "        testplots(paramRanges[flavour], te_results, TRUE_CONN, logx=False, percenty=True, pTHR=0.01, h5_fname=fname+'.h5', fig_fname=fname+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window / Lag / Downsample Analysis\n",
    "\n",
    "This analysis studies T1 error as function of implicit parameters of the analysis. Those parameters are:\n",
    "* **Window** - How many timesteps are grouped together in a sweep-window to estimate time-dependent TE\n",
    "* **Lag** - How many timesteps of past history to consider when estimating FC. Lag $<$ Window\n",
    "* **Downsampling** - T1 error as function of downsampling rate ($\\Delta t_2 / \\Delta t_1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stat_te(te_results, TRUE_CONN, pTHR=0.01):\n",
    "    _, N_NODE, _, N_TIMES = te_results.shape\n",
    "    \n",
    "    te_results_copy = np.copy(te_results)\n",
    "    te, lag, p = te_results_copy\n",
    "    \n",
    "    p[np.isnan(p)] = 100\n",
    "    noconn_idx = p > pTHR\n",
    "    te[noconn_idx] = np.nan\n",
    "    \n",
    "    test_fp = merge_dicts([accuracyTests(te[:, :, i], TRUE_CONN) for i in range(N_TIMES)])\n",
    "    \n",
    "    mu_dict  = {key : np.mean(val) for key, val in test_fp.items()}\n",
    "    sig_dict = {key : np.std(val) for key, val in test_fp.items()}\n",
    "    \n",
    "    return mu_dict, sig_dict\n",
    "\n",
    "def statplots(xval, stat, xlabel, fig_fname=None):\n",
    "    stat_mu  = merge_dicts([s[0] for s in stat])\n",
    "    stat_sig = merge_dicts([s[1] for s in stat])\n",
    "    \n",
    "    #####################################\n",
    "    # Plot\n",
    "    #####################################\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    ax.set_title(\"Error rates\")\n",
    "    ax.set_xlabel(xlabel)\n",
    "\n",
    "    ax.errorbar(xval, stat_mu[\"FalsePositiveRate\"], yerr=stat_sig[\"FalsePositiveRate\"], label='FP_RATE')\n",
    "    ax.errorbar(xval, stat_mu[\"FalseNegativeRate\"], yerr=stat_sig[\"FalseNegativeRate\"], label='FN_RATE')\n",
    "    ax.legend()\n",
    "    \n",
    "    if fig_fname is not None:\n",
    "        plt.savefig(fig_fname, dpi=300)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "###############################\n",
    "# Window / Lag / Downsampling\n",
    "###############################\n",
    "'''\n",
    "TODO:\n",
    "+) Import resampling\n",
    "2) Implement stat collection\n",
    "3) Implement statplots\n",
    "'''\n",
    "\n",
    "N_NODE = 12\n",
    "N_TRIAL = 400\n",
    "N_DATA = 200\n",
    "DT = 0.05     # seconds, natural delay time\n",
    "\n",
    "f_log = open(\"log.txt\", \"w\")\n",
    "f_log.close()\n",
    "def write_log(fname, s):\n",
    "    with open(\"log.txt\", \"a\") as f:\n",
    "        f.write(s + \"\\n\")\n",
    "\n",
    "\n",
    "idtxl_settings['dim_order'] = 'rsp'\n",
    "idtxl_methods = ['BivariateMI', 'MultivariateMI', 'BivariateTE', 'MultivariateTE']\n",
    "\n",
    "for modelname, model_param in model_param_all.items():\n",
    "    TRUE_CONN = TRUE_CONN_DICT[modelname]\n",
    "\n",
    "    ###################################\n",
    "    # Generate data - takes some time\n",
    "    ###################################\n",
    "    write_log(f_log, str([\"Generating Data\", modelname]))\n",
    "\n",
    "    model_param['N_NODE'] = N_NODE\n",
    "    model_param['DT'] = DT\n",
    "    model_param['N_DATA'] = N_DATA\n",
    "    model_param['T_TOT' ] = N_DATA * DT\n",
    "    \n",
    "    # Generate each trial independently, then concatenate\n",
    "    data = np.array([model_param['method'](model_param) for j in range(N_TRIAL)]).transpose((0, 2, 1))\n",
    "    \n",
    "    # FIXME: Crop data to NDATA in case there is tail\n",
    "    data = data[:, :N_DATA, :]\n",
    "    \n",
    "    ###################################\n",
    "    # Window\n",
    "    ###################################\n",
    "    idtxl_settings['min_lag_sources'] = 1\n",
    "    idtxl_settings['max_lag_sources'] = 1\n",
    "    \n",
    "    wlen = np.arange(2, 11)\n",
    "    for method in idtxl_methods:\n",
    "        stat = []\n",
    "        \n",
    "        for window in wlen:\n",
    "            write_log(f_log, str([\"Processing Window Data\", modelname, method]))\n",
    "            \n",
    "            idtxl_settings['method'] = method                    \n",
    "            te_results = np.zeros((3, N_NODE, N_NODE, N_DATA - window))\n",
    "            \n",
    "            for iTime in range(N_DATA - window):\n",
    "                write_log(f_log, str([\"--- \", iTime]))\n",
    "                \n",
    "                # Run calculation\n",
    "                rez = idtxlParallelCPU(data[:, iTime:iTime+window, :], idtxl_settings)\n",
    "\n",
    "                # Parse Data\n",
    "                te_results[..., iTime] = np.array(idtxlResultsParse(rez, N_NODE, method=method, storage='matrix'))\n",
    "                \n",
    "            stat += [stat_te(te_results, TRUE_CONN, pTHR=0.01)]\n",
    "            \n",
    "        # Plot\n",
    "        fname = \"window_\" + modelname + '_' + str(N_NODE) + method\n",
    "        statplots(wlen, stat, xlabel=\"window\", fig_fname=fname+'.png')\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    # Lag\n",
    "    ###################################\n",
    "    window = 6\n",
    "    idtxl_settings['min_lag_sources'] = 1\n",
    "    \n",
    "    maxlag_lst = np.arange(1, 6)\n",
    "    for method in idtxl_methods:\n",
    "        stat = []\n",
    "        \n",
    "        for maxlag in maxlag_lst:\n",
    "            write_log(f_log, str([\"Processing Lag Data\", modelname, method, maxlag]))\n",
    "            \n",
    "            idtxl_settings['method'] = method\n",
    "            idtxl_settings['max_lag_sources'] = maxlag\n",
    "            \n",
    "            te_results = np.zeros((3, N_NODE, N_NODE, N_DATA - window))\n",
    "            \n",
    "            for iTime in range(N_DATA - window):\n",
    "                write_log(f_log, str([\"--- \", iTime]))\n",
    "                \n",
    "                # Run calculation\n",
    "                rez = idtxlParallelCPU(data[:, iTime:iTime+window, :], idtxl_settings)\n",
    "\n",
    "                # Parse Data\n",
    "                te_results[..., iTime] = np.array(idtxlResultsParse(rez, N_NODE, method=method, storage='matrix'))\n",
    "                \n",
    "            stat += [stat_te(te_results, TRUE_CONN, pTHR=0.01)]\n",
    "            \n",
    "        # Plot\n",
    "        fname = \"lag_\" + modelname + '_' + str(N_NODE) + method\n",
    "        statplots(maxlag_lst, stat, xlabel=\"lag\", fig_fname=fname+'.png')\n",
    "    \n",
    "    \n",
    "    ###################################\n",
    "    # Downsampling\n",
    "    ###################################\n",
    "    window = 6\n",
    "    idtxl_settings['min_lag_sources'] = 1\n",
    "    idtxl_settings['max_lag_sources'] = 5\n",
    "    \n",
    "    downsample_times = [DT] + list(np.arange(0.1, 0.6, 0.1))\n",
    "    \n",
    "    stat_dict = {method : [] for method in idtxl_methods}\n",
    "    for dt_down in downsample_times:\n",
    "        write_log(f_log, str([\"Generating Downsample Data for\", modelname]))\n",
    "\n",
    "        idtxl_settings['method'] = method\n",
    "        param_down = {'method' : 'averaging', 'kind' : 'kernel'}\n",
    "\n",
    "        # Downsample data\n",
    "        if dt_down == DT:\n",
    "            data_downsampled = np.copy(data)\n",
    "        else:\n",
    "            times_orig = np.arange(0, model_param['T_TOT'], DT)\n",
    "            times_down = np.arange(0, model_param['T_TOT'], dt_down)\n",
    "            N_DATA_DOWN = len(times_down)\n",
    "            data_downsampled = np.zeros((N_TRIAL, N_DATA_DOWN, N_NODE))\n",
    "\n",
    "            for iTr in range(N_TRIAL):\n",
    "                for iNode in range(N_NODE):\n",
    "                    data_downsampled[iTr, :, iNode] = resample(times_orig, data[iTr, :, iNode], times_down, param_down)\n",
    "\n",
    "                    \n",
    "        for method in idtxl_methods:\n",
    "            te_results = np.zeros((3, N_NODE, N_NODE, N_DATA_DOWN - window))\n",
    "\n",
    "            for iTime in range(N_DATA_DOWN - window):\n",
    "                write_log(f_log, str([\"--- \", method, iTime]))\n",
    "                \n",
    "                # Run calculation\n",
    "                rez = idtxlParallelCPU(data_downsampled[:, iTime:iTime+window, :], idtxl_settings)\n",
    "\n",
    "                # Parse Data\n",
    "                te_results[..., iTime] = np.array(idtxlResultsParse(rez, N_NODE, method=method, storage='matrix'))\n",
    "\n",
    "            stat_dict[method] += [stat_te(te_results, TRUE_CONN, pTHR=0.01)]\n",
    "\n",
    "    # Plot\n",
    "    for method in idtxl_methods:\n",
    "        fname = \"downsample_\" + modelname + '_' + str(N_NODE) + method\n",
    "        statplots(downsample_times, stat_dict[method], xlabel=\"timestep\", fig_fname=fname+'.png')\n",
    "        \n",
    "f_log.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nest)",
   "language": "python",
   "name": "py36nest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}